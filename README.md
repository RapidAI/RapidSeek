# RapidSeek
An Economical Large Language Model Inference Cluster System for DeepSeek MOE Models (such as DeepSeek V3 and R1)


# Featurs:

- C++ and Python-based 
- efficient kernels in C++ 
- for multiple machine clusters with a cost below 1,500 dollars per machine
- supporting 20 tokens per second per user.

## Models supported
* DeepSeek-V2-Lite 

* DeepSeekV3

* DeepSeekR1

### Supported  GPUs
- Nvidia
- AMD
- Intel Arc
  
### Recommended hardware


### Special thanks to 

- llamafile https://github.com/Mozilla-Ocho/llamafile
- Marlin  https://github.com/IST-DASLab/marlin
